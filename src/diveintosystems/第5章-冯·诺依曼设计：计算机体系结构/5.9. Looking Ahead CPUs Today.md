## 5.9. Looking Ahead: CPUs Today

CPU pipelining is one example of **instruction-level parallelism** (ILP), in which the CPU simultaneously executes multiple instructions in parallel. In a pipelined execution, the CPU simultaneously executes multiple instructions by overlapping their execution in the pipeline. A simple pipelined CPU can achieve a CPI of 1, completing the execution of one instruction every clock cycle. Modern microprocessors typically employ pipelining along with other ILP techniques and include multiple CPU cores to achieve processor CPI values of less than 1. For these microarchitectures, the average number of **instructions per cycle** (IPC) is the metric commonly used to describe their performance. A large IPC value indicates that a processor achieves a high sustained degree of simultaneous instruction execution.
CPU 流水线是指令级并行 (ILP) 的一个示例，其中 CPU 同时并行执行多个指令。在流水线执行中，CPU 通过在流水线中重叠执行来同时执行多个指令。简单的流水线 CPU 可以实现 1 的 CPI，每个时钟周期完成一条指令的执行。现代微处理器通常采用流水线和其他 ILP 技术，并包含多个 CPU 核心来实现小于 1 的处理器 CPI 值。对于这些微架构，平均每周期指令数 (IPC) 是通常用于描述其性能的指标。较大的 IPC 值表示处理器实现了高持续程度的同时指令执行。

Transistors are the building blocks of all circuitry on an integrated circuit (a chip). The processing and control units of modern CPUs are constructed from circuits, which are built from subcircuits and basic logic gates that are implemented with transistors. Transistors also implement the storage circuits used in CPU registers and in fast on-chip cache memory that stores copies of recently accessed data and instructions (we discuss cache memory in detail in [Chapter 11](https://diveintosystems.org/book/C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy)).
晶体管是集成电路（芯片）上所有电路的构建块。现代 CPU 的处理和控制单元由电路构成，而电路则由使用晶体管实现的子电路和基本逻辑门构成。晶体管还实现了 CPU 寄存器和快速片上高速缓存中使用的存储电路，用于存储最近访问的数据和指令的副本（我们将在 [第 11 章](https://diveintosystems.org/book/C11-MemHierarchy/index.html#_storage_and_the_memory_hierarchy) 中详细讨论高速缓存）。

The number of transistors that can fit on a chip is a rough measure of its performance. **Moore’s Law** is the observation, made by Gordon Moore in 1975, that the number of transistors per integrated circuit doubles about every two years1,2. A doubling in the number of transistors per chip every two years means that computer architects can design a new chip with twice as much space for storage and computation circuitry, roughly doubling its power. Historically, computer architects used the extra transistors to design more complex single processors using ILP techniques to improve overall performance.
芯片上可容纳的晶体管数量是衡量芯片性能的粗略标准。**摩尔定律**是戈登·摩尔于 1975 年提出的观察结果，即每个集成电路上的晶体管数量大约每两年翻一番1,2。每两年每个芯片上的晶体管数量翻一番意味着计算机架构师可以设计出一种新芯片，其存储和计算电路空间增加一倍，功率大约增加一倍。从历史上看，计算机架构师使用额外的晶体管来设计更复杂的单处理器，并使用 ILP 技术来提高整体性能。

### [](https://diveintosystems.org/book/C5-Arch/modern.html#_instruction_level_parallelism)5.9.1. Instruction-Level Parallelism指令级并行

Instruction level parallelism (ILP) is a term for a set of design techniques used to support parallel execution of a single program’s instructions on a single processor. ILP techniques are transparent to the programmer, meaning that a programmer writes a sequential C program but the processor executes several of its instructions simultaneously, in parallel, on one or more execution units. Pipelining is one example of ILP, where a sequence of program instructions execute simultaneously, each in a different pipeline stage. A pipelined processor can execute one instruction per cycle (can achieve an IPC of 1). Other types of microprocessor ILP designs can execute more than a single instruction per clock cycle and achieve IPC values higher than 1.
指令级并行 (ILP) 是指一组设计技术，用于支持在单个处理器上并行执行单个程序的指令。ILP 技术对程序员来说是透明的，这意味着程序员编写一个顺序 C 程序，但处理器在一个或多个执行单元上同时并行执行其多条指令。流水线是 ILP 的一个示例，其中程序指令序列同时执行，每条指令都在不同的流水线阶段中执行。流水线处理器每个周期可以执行一条指令（可以实现 1 的 IPC）。其他类型的微处理器 ILP 设计可以在每个时钟周期执行多条指令，并实现高于 1 的 IPC 值。

A **vector processor** is an architecture that implements ILP through special vector instructions that take one-dimensional arrays (vectors) of data as their operands. Vector instructions are executed in parallel by a vector processor on multiple execution units, each unit performing an arithmetic operation on single elements of its vector operands. In the past, vector processors were often used in large parallel computers. The 1976 Cray-1 was the first vector processor-based supercomputer, and Cray continued to design its supercomputers with vector processors throughout the 1990s. However, eventually this design could not compete with other parallel supercomputer designs, and today vector processors appear primarily in accelerator devices such as graphics processing units (GPUs) that are particularly optimized for performing computation on image data stored in 1D arrays.
**矢量处理器** 是一种通过特殊矢量指令实现 ILP 的架构，这些矢量指令以一维数据数组（矢量）作为操作数。矢量指令由矢量处理器在多个执行单元上并行执行，每个执行单元对其矢量操作数的单个元素执行算术运算。过去，矢量处理器通常用于大型并行计算机。1976 年的 Cray-1 是第一台基于矢量处理器的超级计算机，Cray 在整个 20 世纪 90 年代继续使用矢量处理器设计超级计算机。然而，这种设计最终无法与其他并行超级计算机设计竞争，如今矢量处理器主要出现在加速器设备中，例如图形处理单元 (GPU)，这些设备特别针对对存储在一维数组中的图像数据执行计算进行了优化。

**Superscalar** is another example of an ILP processor design. A superscalar processor is a single processor with multiple execution units and multiple execution pipelines. A superscalar processor fetches a set of instructions from a sequential program’s instruction stream, and breaks them up into multiple independent streams of instructions that are executed in parallel by its execution units. A superscalar processor is an **out-of-order processor**, or one that executes instructions out of the order in which they appear in a sequential instruction stream. Out-of-order execution requires identifying sequences of instructions without dependencies that can safely execute in parallel. A superscalar processor contains functionality to dynamically create the multiple streams of independent instructions to feed through its multiple execution units. This functionality must perform dependency analysis to ensure the correct ordering of any instruction whose execution depends on the result of a previous instruction in these sequential streams. As an example, a superscalar processor with five pipelined execution units can execute five instructions from a sequential program in a single cycle (can achieve an IPC of 5). However, due to instruction dependencies, it is not always the case that a superscalar processor can keep all of its pipelines full.
**超标量**是 ILP 处理器设计的另一个示例。超标量处理器是具有多个执行单元和多个执行流水线的单个处理器。超标量处理器从顺序程序的指令流中获取一组指令，并将它们分解为多个独立的指令流，由其执行单元并行执行。超标量处理器是一种**无序处理器**，即执行指令的顺序与指令在顺序指令流中的出现顺序不符。无序执行需要识别可以安全并行执行的没有依赖关系的指令序列。超标量处理器包含动态创建多个独立指令流以通过其多个执行单元的功能。此功能必须执行依赖性分析，以确保任何指令的执行都依赖于这些顺序流中前一条指令的结果，其顺序正确。例如，具有五个流水线执行单元的超标量处理器可以在一个周期内执行来自顺序程序的五条指令（可以实现 5 的 IPC）。然而，由于指令依赖性，超标量处理器并不总是能够保持所有流水线都处于满负荷状态。

**Very long instruction word** (VLIW) is another ILP microarchitecture design that is similar to superscalar. In VLIW architectures, however, the compiler is responsible for constructing the multiple independent instruction streams executed in parallel by the processor. A compiler for a VLIW architecture analyzes the program instructions to statically construct a VLIW instruction that consists of multiple instructions, one from each independent stream. VLIW leads to simpler processor design than superscalar because the VLIW processor does not need to perform dependency analysis to construct the multiple independent instruction streams as part of its execution of program instructions. Instead, a VLIW processor just needs added circuitry to fetch the next VLIW instruction and break it up into its multiple instructions that it feeds into each of its execution pipelines. However, by pushing dependency analysis to the compiler, VLIW architectures require specialized compilers to achieve good performance.
**超长指令字** (VLIW) 是另一种类似于超标量的 ILP 微架构设计。然而，在 VLIW 架构中，编译器负责构建由处理器并行执行的多个独立指令流。VLIW 架构的编译器会分析程序指令，以静态构建由多条指令组成的 VLIW 指令，每个独立指令流各一条。VLIW 的处理器设计比超标量更简单，因为 VLIW 处理器不需要执行依赖性分析来构建多个独立指令流作为其执行程序指令的一部分。相反，VLIW 处理器只需要添加电路来获取下一个 VLIW 指令并将其分解为多条指令，然后将其输入到每个执行管道中。但是，通过将依赖性分析推送到编译器，VLIW 架构需要专门的编译器才能实现良好的性能。

One problem with both superscalar and VLIW is that the degree of parallel performance is often significantly limited by the sequential application programs they execute. Dependencies between instructions in the program limit the ability to keep all of the pipelines full.
超标量和 VLIW 都存在一个问题，即并行性能的程度通常受到它们执行的顺序应用程序的严重限制。程序中指令之间的依赖关系限制了保持所有流水线满负荷的能力。
### [](https://diveintosystems.org/book/C5-Arch/modern.html#_multicore_and_hardware_multithreading)5.9.2. Multicore and Hardware Multithreading多核和硬件多线程

By designing single processors that employed increasingly complicated ILP techniques and increasing the CPU clock speed to drive this increasingly complicated functionality, computer architects designed processors whose performance kept pace with Moore’s Law until the early 2000s. After this time, CPU clock speeds could no longer increase without greatly increasing a processor’s power consumption3. This led to the current era of multicore and multithreaded microarchitectures, both of which require _explicit parallel programming_ by a programmer to speed up the execution of a single program.
通过设计采用日益复杂的 ILP 技术的单个处理器并提高 CPU 时钟速度来驱动日益复杂的功能，计算机架构师设计出的处理器的性能直到 21 世纪初都与摩尔定律保持同步。在此之后，如果不大幅增加处理器的功耗，CPU 时钟速度就无法再提高3。这导致了当前多核和多线程微架构时代的到来，这两者都需要程序员进行_显式并行编程_来加快单个程序的执行速度。

**Hardware multithreading** is a single-processor design that supports executing multiple hardware threads. A **thread** is an independent stream of execution. For example, two running programs each have their own thread of independent execution. These two programs' threads of execution could then be scheduled by the operating system to run "at the same time" on a multithreaded processor. Hardware multithreading may be implemented by a processor alternating between executing instructions from each of its threads' instruction streams each cycle. In this case, the instructions of different hardware threads are not all executed simultaneously each cycle. Instead, the processor is designed to quickly switch between executing instructions from different threads' execution streams. This usually results in a speed-up of their execution as a whole as compared to their execution on a singly threaded processor.
**硬件多线程** 是一种支持执行多个硬件线程的单处理器设计。**线程** 是独立的执行流。例如，两个正在运行的程序各自都有自己的独立执行线程。然后，操作系统可以调度这两个程序的执行线程在多线程处理器上“同时”运行。硬件多线程可以通过处理器在每个周期交替执行来自其每个线程的指令流的指令来实现。在这种情况下，不同硬件线程的指令并不是每个周期都同时执行。相反，处理器被设计为在执行来自不同线程的执行流的指令之间快速切换。与在单线程处理器上执行相比，这通常会导致它们整体的执行速度加快。

Multithreading can be implemented in hardware on either scalar- or super-scalar type microprocessors. At a minimum, the hardware needs to support fetching instructions from multiple separate instruction streams (one for each thread of execution), and have separate register sets for each thread’s execution stream. These architectures are **explicitly multithreaded**4 because, unlike superscalar architectures, each of the execution streams is independently scheduled by the operating system to run a separate logical sequence of program instructions. The multiple execution streams could come from multiple sequential programs or from multiple software threads from a single multithreaded parallel program (we discuss multithreaded parallel programming in [Chapter 14](https://diveintosystems.org/book/C14-SharedMemory/multicore.html#_programming_multicore_systems)).
多线程可以在标量或超标量类型微处理器的硬件中实现。至少，硬件需要支持从多个单独的指令流（每个执行线程一个）获取指令，并为每个线程的执行流提供单独的寄存器集。这些架构**显式多线程**4，因为与超标量架构不同，每个执行流都由操作系统独立调度，以运行单独的程序指令逻辑序列。多个执行流可以来自多个顺序程序，也可以来自单个多线程并行程序的多个软件线程（我们在第 14 章中讨论多线程并行编程）。

Hardware multithreaded microarchitectures that are based on superscalar processors have multiple pipelines and multiple execution units, and thus they can execute instructions from several hardware threads simultaneously, in parallel, resulting in an IPC value greater than 1. Multithreaded architectures based on simple scalar processors implement **interleaved multithreading**. These microarchitectures typically share a pipeline and always share the processor’s single ALU (the CPU switches between executing different threads on the ALU). This type of multithreading cannot achieve IPC values greater than 1. Hardware threading supported by superscalar-based microarchitectures is often called **simultaneous multithreading** (SMT)4. Unfortunately, SMT is often used to refer to both types of hardware multithreading, and the term alone is not always sufficient to determine whether a multithreaded microarchitecture implements true simultaneous or interleaved multithreading.
基于超标量处理器的硬件多线程微架构具有多个流水线和多个执行单元，因此它们可以同时并行执行来自多个硬件线程的指令，从而导致 IPC 值大于 1。基于简单标量处理器的多线程架构实现**交错多线程**。这些微架构通常共享一个流水线，并且始终共享处理器的单个 ALU（CPU 在 ALU 上切换执行不同线程）。这种类型的多线程无法实现大于 1 的 IPC 值。基于超标量的微架构支持的硬件线程通常称为**同步多线程** (SMT)4。不幸的是，SMT 通常用于指代两种类型的硬件多线程，仅凭这个术语并不总是足以确定多线程微架构是实现真正的同步多线程还是交错多线程。

**Multicore processors** contain multiple complete CPU cores. Like multithreaded processors, each core is independently scheduled by the OS. However, each core of a multicore processor is a full CPU core, one that contains its own complete and separate functionality to execute program instructions. A multicore processor contains replicas of these CPU cores with some additional hardware support for the cores to share cached data. Each core of a multicore processor could be scalar, superscalar, or hardware multithreaded. [Figure 1](https://diveintosystems.org/book/C5-Arch/modern.html#Figmulticoreprocesor) shows an example of a multicore computer.
**多核处理器** 包含多个完整的 CPU 核心。与多线程处理器一样，每个核心都由操作系统独立调度。但是，多核处理器的每个核心都是一个完整的 CPU 核心，包含自己完整且独立的功能来执行程序指令。多核处理器包含这些 CPU 核心的副本，并为核心提供一些额外的硬件支持，以共享缓存数据。多核处理器的每个核心都可以是标量、超标量或硬件多线程的。[图 1](https://diveintosystems.org/book/C5-Arch/modern.html#Figmulticoreprocesor) 展示了多核计算机的一个例子。

![a multicore computer showing the processor chip with multiple CPU cores](https://diveintosystems.org/book/C5-Arch/_images/multicore.png)

Figure 1. A computer with a multicore processor. The processor contains multiple complete CPU cores, each with its own private cache memory. The cores communicate with each and share a larger shared cached memory via on-chip buses.
图 1. 带有多核处理器的计算机。处理器包含多个完整的 CPU 内核，每个内核都有自己的专用缓存。内核之间通过片上总线进行通信，并共享更大的共享缓存。

Multicore microprocessor design is the primary way in which the performance of processor architectures can continue to keep pace with Moore’s Law without increasing the processor clock rate. A multicore computer can simultaneously run several sequential programs, the OS scheduling each core with a different program’s instruction stream. It can speed up execution of a single program if the program is written as an explicitly multithreaded (software-level threads) parallel program. For example, the OS can schedule the threads of an individual program to run simultaneously on individual cores of the multicore processor, speeding up the execution of the program compared to its execution of a sequential version of the same program. In [Chapter 14](https://diveintosystems.org/book/C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era), we discuss explicit multithreaded parallel programming for multicore and other types of parallel systems with shared main memory.

多核微处理器设计是处理器架构性能在不提高处理器时钟频率的情况下继续与摩尔定律保持同步的主要方式。多核计算机可以同时运行多个顺序程序，操作系统使用不同程序的指令流调度每个内核。如果程序编写为显式多线程（软件级线程）并行程序，则可以加快单个程序的执行速度。例如，操作系统可以调度单个程序的线程在多核处理器的各个内核上同时运行，与执行同一程序的顺序版本相比，可以加快程序的执行速度。在[第 14 章](https://diveintosystems.org/book/C14-SharedMemory/index.html#_leveraging_shared_memory_in_the_multicore_era)中，我们讨论了多核和其他类型的具有共享主内存的并行系统的显式多线程并行编程。

### [](https://diveintosystems.org/book/C5-Arch/modern.html#_some_example_processors)5.9.3. Some Example Processors一些示例处理器

Today, processors are built using a mix of ILP, hardware multithreading, and multicore technologies. In fact, it is difficult to find a processor that is not multicore. Desktop-class processors typically have two to eight cores, many of which also support a low level of per-core multithreading. For example, AMD Zen multicore processors5 and Intel’s hyperthreaded multicore Xeon and Core processors6 both support two hardware threads per core. Intel’s hyperthreaded cores implement interleaved multithreading. Thus, each of its cores can only achieve an IPC of 1, but with multiple CPU cores per chip, the processor can achieve higher IPC levels.
如今，处理器是使用 ILP、硬件多线程和多核技术混合构建的。事实上，很难找到非多核的处理器。桌面级处理器通常有 2 到 8 个内核，其中许多内核还支持低级别的每核多线程。例如，AMD Zen 多核处理器5 和英特尔的超线程多核 Xeon 和 Core 处理器6 都支持每核两个硬件线程。英特尔的超线程内核实现了交错多线程。因此，其每个内核只能实现 1 的 IPC，但如果每个芯片有多个 CPU 内核，处理器可以实现更高的 IPC 级别。

Processors designed for high-end systems, such as those used in servers and supercomputers, contain many cores, where each core has a high degree of multithreading. For example, Oracle’s SPARC M7 processor7, used in high-end servers, has 32 cores. Each of its cores has eight hardware threads, two of which can execute simultaneously, resulting in a maximum IPC value of 64 for the processor. The two fastest supercomputers in the world (as of June 2019)8, use IBM’s Power 9 processors9. Power 9 processors have up to 24 cores per chip, and each core supports up to eight-way simultaneous multithreading. A 24-core version of the Power 9 processor can achieve an IPC of 192.
为高端系统设计的处理器（例如用于服务器和超级计算机的处理器）包含许多内核，每个内核都具有高度的多线程。例如，用于高端服务器的 Oracle SPARC M7 处理器7 有 32 个内核。每个内核都有八个硬件线程，其中两个可以同时执行，从而使处理器的最大 IPC 值为 64。世界上最快的两台超级计算机（截至 2019 年 6 月）8 使用 IBM 的 Power 9 处理器9。Power 9 处理器每个芯片最多有 24 个内核，每个内核支持最多八路同时多线程。24 核版本的 Power 9 处理器可以实现 192 的 IPC。
### 脚注和参考文献

1. Moore first observed a doubling every year in 1965, that he then updated in 1975 to every > 2 years, which became known as Moore’s Law.
2. Moore’s Law held until around 2012 when improvements in transistor density began to slow. Moore predicted the end of Moore’s Law in the mid 2020s.
3. "The End of Dennard scaling" by Adrian McMenamin, 2013. [https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/](https://cartesianproduct.wordpress.com/2013/04/15/the-end-of-dennard-scaling/)
4. "A Survey of Processors with Explicit Multithreading", by Ungerer, Robic, and Silc. In ACM Computing Surveys, Vol. 35, No. 1, March 2003, pp. 29–63. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.9105&rep=rep1&type=pdf)
5. AMD’s Zen Architectures: [https://www.amd.com/en/technologies/zen-core](https://www.amd.com/en/technologies/zen-core)
6. Intel’s Xeon and Core processors with Hyper-Threading: [https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html](https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html)
7. Oracle’s SPARC M7 Processor: [http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf](http://www.oracle.com/us/products/servers-storage/sparc-m7-processor-ds-2687041.pdf)
8. Top 500 Lists: [https://www.top500.org/lists/top500/](https://www.top500.org/lists/top500/)
9. IBM’s Power 9 Processor: [https://www.ibm.com/it-infrastructure/power/power9](https://www.ibm.com/it-infrastructure/power/power9)